# ğŸ“ RAGä½œæ–‡æ•™å­¦ç³»ç»Ÿ - ä»£ç å­¦ä¹ æŒ‡å—

> è¿™æ˜¯ä¸€ä»½è¯¦ç»†çš„ä»£ç å­¦ä¹ æŒ‡å—ï¼Œå¸®åŠ©ä½ ä»é›¶å¼€å§‹ç†è§£æ•´ä¸ªRAGä½œæ–‡æ•™å­¦ç³»ç»Ÿçš„ä»£ç å®ç°ã€‚

## ğŸ“š å­¦ä¹ è·¯å¾„

### ç¬¬ä¸€æ­¥ï¼šç†è§£æ•°æ®æ¨¡å‹ï¼ˆå¿…è¯»ï¼‰
ä» `src/core/models.py` å¼€å§‹ï¼Œè¿™æ˜¯æ•´ä¸ªç³»ç»Ÿçš„"è¯­è¨€"

### ç¬¬äºŒæ­¥ï¼šæŒæ¡ç³»ç»Ÿé…ç½®
å­¦ä¹  `src/core/config.py`ï¼Œäº†è§£ç³»ç»Ÿå¦‚ä½•é…ç½®

### ç¬¬ä¸‰æ­¥ï¼šç†è§£çŸ¥è¯†åº“æ¶æ„
æŒ‰é¡ºåºå­¦ä¹  `knowledge/` æ¨¡å—

### ç¬¬å››æ­¥ï¼šæŒæ¡æ£€ç´¢æœºåˆ¶
å­¦ä¹  `retrieval/` æ¨¡å—çš„å„ä¸ªç»„ä»¶

### ç¬¬äº”æ­¥ï¼šäº†è§£ç”Ÿæˆé€»è¾‘
å­¦ä¹  `generation/` æ¨¡å—

### ç¬¬å…­æ­¥ï¼šæŒæ¡ç³»ç»Ÿé›†æˆ
å­¦ä¹ ä¸»ç³»ç»Ÿ `rag_system.py`

### ç¬¬ä¸ƒæ­¥ï¼šäº†è§£APIæ¥å£
å­¦ä¹  `api/` æ¨¡å—

---

## ğŸ“– è¯¦ç»†ä»£ç è®²è§£

## 1. æ•°æ®æ¨¡å‹ (src/core/models.py) ğŸ“Š

è¿™æ˜¯ç³»ç»Ÿçš„"è¯æ±‡è¡¨"ï¼Œå®šä¹‰äº†æ‰€æœ‰æ•°æ®ç»“æ„ã€‚

### æ ¸å¿ƒæ¦‚å¿µï¼š

#### WritingTopic - ä½œæ–‡é¢˜ç›®
```python
class WritingTopic(BaseModel):
    """ä½œæ–‡é¢˜ç›®æ•°æ®æ¨¡å‹"""
    id: str                    # å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå¦‚ "topic_001"
    title: str                 # é¢˜ç›®æ ‡é¢˜ï¼Œå¦‚ "æˆ‘çš„å®¶ä¹¡"
    content: str               # é¢˜ç›®è¦æ±‚æè¿°
    type: str                  # é¢˜ç›®ç±»å‹ï¼šè®°å™æ–‡ã€è®®è®ºæ–‡ã€è¯´æ˜æ–‡ç­‰
    difficulty: int            # éš¾åº¦ç­‰çº§ 1-5 çº§
    keywords: List[str]        # å…³é”®è¯åˆ—è¡¨ï¼Œå¦‚ ["å®¶ä¹¡", "å›å¿†", "æƒ…æ„Ÿ"]
    requirements: Optional[List[str]]  # å†™ä½œè¦æ±‚ï¼Œå¦‚å­—æ•°é™åˆ¶
    created_at: datetime       # åˆ›å»ºæ—¶é—´
```

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**
- `id` å”¯ä¸€æ ‡è¯†ï¼šæ–¹ä¾¿æ•°æ®åº“æ“ä½œå’Œå¼•ç”¨
- `type` é¢˜ç›®åˆ†ç±»ï¼šä¸åŒç±»å‹çš„ä½œæ–‡éœ€è¦ä¸åŒçš„å†™ä½œæŒ‡å¯¼
- `keywords` å…³é”®è¯ï¼šç”¨äºæ£€ç´¢ç›¸å…³ç´ æå’ŒèŒƒæ–‡
- `difficulty` éš¾åº¦åˆ†çº§ï¼šä¸ªæ€§åŒ–æ¨èåŒ¹é…å­¦ç”Ÿæ°´å¹³

#### WritingMaterial - å†™ä½œç´ æ
```python
class WritingMaterial(BaseModel):
    """å†™ä½œç´ ææ•°æ®æ¨¡å‹"""
    id: str                    # ç´ æID
    title: str                 # ç´ ææ ‡é¢˜
    content: str               # å…·ä½“å†…å®¹
    category: str              # åˆ†ç±»ï¼šäººç‰©ã€äº‹ä»¶ã€æ™¯ç‰©ã€é“ç†ç­‰
    keywords: List[str]        # ç›¸å…³å…³é”®è¯
    usage_scenario: List[str]  # é€‚ç”¨åœºæ™¯ï¼šå¼€å¤´ã€ç»“å°¾ã€è®ºè¯ç­‰
    difficulty: int            # é€‚ç”¨éš¾åº¦ç­‰çº§
```

**å®é™…åº”ç”¨ï¼š**
- å­¦ç”Ÿè¾“å…¥"å†™å…³äºå‹è°Šçš„ä½œæ–‡"
- ç³»ç»Ÿé€šè¿‡ `keywords` åŒ¹é…åˆ°ç›¸å…³å‹è°Šç´ æ
- æ ¹æ® `usage_scenario` åˆ†åˆ«æ¨èå¼€å¤´ã€ä¸­é—´ã€ç»“å°¾çš„ç´ æ

#### EssayExample - èŒƒæ–‡ç¤ºä¾‹
```python
class EssayExample(BaseModel):
    """èŒƒæ–‡ç¤ºä¾‹æ•°æ®æ¨¡å‹"""
    id: str                    # èŒƒæ–‡ID
    title: str                 # æ ‡é¢˜
    content: str               # å®Œæ•´å†…å®¹
    type: str                  # ç±»å‹ï¼šè®°å™æ–‡ã€è®®è®ºæ–‡ç­‰
    score: int                 # è¯„åˆ† 1-100
    highlights: List[str]      # äº®ç‚¹åˆ†æ
    structure: Dict[str, str]  # ç»“æ„åˆ†æï¼š{"å¼€å¤´": "...", "æ­£æ–‡": "...", "ç»“å°¾": "..."}
    keywords: List[str]        # å…³é”®è¯
```

**å­¦ä¹ ä»·å€¼ï¼š**
- `structure` å¸®åŠ©å­¦ç”Ÿç†è§£ä¼˜ç§€ä½œæ–‡çš„ç»“æ„
- `highlights` æŒ‡å‡ºå€¼å¾—å­¦ä¹ çš„å†™ä½œæŠ€å·§
- `score` æä¾›è´¨é‡å‚è€ƒ

## 2. ç³»ç»Ÿé…ç½® (src/core/config.py) âš™ï¸

### é…ç½®ç®¡ç†åŸç†ï¼š

```python
class AppConfig:
    """åº”ç”¨é…ç½®ç±»"""

    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®ï¼Œæä¾›é»˜è®¤å€¼
        self.knowledge_base_path = os.getenv('KNOWLEDGE_BASE_PATH', 'data/knowledge')
        self.vector_db_path = os.getenv('VECTOR_DB_PATH', 'data/vectordb')
        self.openai_api_key = os.getenv('OPENAI_API_KEY', '')

    @classmethod
    def from_env_file(cls, env_path: str = '.env'):
        """ä».envæ–‡ä»¶åŠ è½½é…ç½®"""
        # åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼Œç„¶ååˆ›å»ºé…ç½®å®ä¾‹
```

**ä¸ºä»€ä¹ˆç”¨ç¯å¢ƒå˜é‡ï¼Ÿ**
1. **å®‰å…¨æ€§**ï¼šAPIå¯†é’¥ä¸ä¼šå‡ºç°åœ¨ä»£ç ä¸­
2. **çµæ´»æ€§**ï¼šä¸åŒç¯å¢ƒï¼ˆå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ï¼‰ä½¿ç”¨ä¸åŒé…ç½®
3. **æ ‡å‡†åŒ–**ï¼šéµå¾ª12-factoråº”ç”¨åŸåˆ™

**é…ç½®ä¼˜å…ˆçº§ï¼š**
```
ç¯å¢ƒå˜é‡ > .envæ–‡ä»¶ > é»˜è®¤å€¼
```

## 3. çŸ¥è¯†åº“æ¶æ„ (src/knowledge/) ğŸ“š

### 3.1 åŸºç¡€æ¥å£è®¾è®¡ (base.py)

```python
class KnowledgeBase(ABC):
    """çŸ¥è¯†åº“æŠ½è±¡åŸºç±»"""

    @abstractmethod
    async def search_materials(self, query: str, **kwargs) -> List[WritingMaterial]:
        """æœç´¢å†™ä½œç´ æ"""
        pass

    @abstractmethod
    async def search_examples(self, query: str, **kwargs) -> List[EssayExample]:
        """æœç´¢èŒƒæ–‡ç¤ºä¾‹"""
        pass
```

**è®¾è®¡æ¨¡å¼ï¼šæŠ½è±¡å·¥å‚æ¨¡å¼**
- å®šä¹‰ç»Ÿä¸€æ¥å£
- æ”¯æŒå¤šç§çŸ¥è¯†åº“å®ç°ï¼ˆæœ¬åœ°æ–‡ä»¶ã€æ•°æ®åº“ã€äº‘å­˜å‚¨ç­‰ï¼‰
- ä¾¿äºæ‰©å±•å’Œæ›¿æ¢

### 3.2 æœ¬åœ°å®ç° (local_kb.py)

```python
class LocalKnowledgeBase(KnowledgeBase):
    """æœ¬åœ°æ–‡ä»¶çŸ¥è¯†åº“å®ç°"""

    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.materials: List[WritingMaterial] = []
        self.examples: List[EssayExample] = []

    async def load_data(self):
        """åŠ è½½æœ¬åœ°æ•°æ®æ–‡ä»¶"""
        # 1. è¯»å–JSONæ–‡ä»¶
        # 2. è§£æä¸ºæ•°æ®æ¨¡å‹
        # 3. å­˜å‚¨åˆ°å†…å­˜ä¸­
```

**æ•°æ®å­˜å‚¨ç­–ç•¥ï¼š**
- JSONæ ¼å¼å­˜å‚¨ï¼šäººç±»å¯è¯»ï¼Œæ˜“äºç¼–è¾‘
- å†…å­˜ç¼“å­˜ï¼šæé«˜æŸ¥è¯¢æ€§èƒ½
- å¼‚æ­¥åŠ è½½ï¼šé¿å…é˜»å¡ä¸»çº¿ç¨‹

### 3.3 æ•°æ®åŠ è½½å™¨ (loader.py)

```python
class DataLoader:
    """æ•°æ®åŠ è½½å·¥å…·ç±»"""

    @staticmethod
    def load_materials(file_path: str) -> List[WritingMaterial]:
        """åŠ è½½ç´ ææ•°æ®"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return [WritingMaterial(**item) for item in data]
```

**é”™è¯¯å¤„ç†æœºåˆ¶ï¼š**
```python
try:
    return [WritingMaterial(**item) for item in data]
except ValidationError as e:
    logger.error(f"æ•°æ®æ ¼å¼é”™è¯¯: {e}")
    return []
except FileNotFoundError:
    logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    return []
```

## 4. æ£€ç´¢ç³»ç»Ÿ (src/retrieval/) ğŸ”

### 4.1 æ–‡æœ¬å‘é‡åŒ– (embedding.py)

```python
class EmbeddingService:
    """æ–‡æœ¬å‘é‡åŒ–æœåŠ¡"""

    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        # ä½¿ç”¨é¢„è®­ç»ƒçš„sentence-transformersæ¨¡å‹
        self.model = SentenceTransformer(model_name)

    def encode_text(self, text: str) -> np.ndarray:
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡"""
        return self.model.encode(text, convert_to_numpy=True)

    def encode_batch(self, texts: List[str]) -> np.ndarray:
        """æ‰¹é‡å‘é‡åŒ–"""
        return self.model.encode(texts, convert_to_numpy=True)
```

**å‘é‡åŒ–åŸç†ï¼š**
1. **é¢„è®­ç»ƒæ¨¡å‹**ï¼šä½¿ç”¨å¤§é‡æ–‡æœ¬è®­ç»ƒçš„ç¥ç»ç½‘ç»œ
2. **è¯­ä¹‰è¡¨ç¤º**ï¼šç›¸ä¼¼å«ä¹‰çš„æ–‡æœ¬åœ¨å‘é‡ç©ºé—´ä¸­è·ç¦»è¾ƒè¿‘
3. **ç»´åº¦å‹ç¼©**ï¼šå°†æ–‡æœ¬æ˜ å°„åˆ°å›ºå®šç»´åº¦çš„å‘é‡ç©ºé—´

### 4.2 å‘é‡æ•°æ®åº“ (vector_store.py)

```python
class SimpleVectorStore:
    """ç®€å•å‘é‡æ•°æ®åº“"""

    def __init__(self, dimension: int = 384):
        self.dimension = dimension
        self.vectors: np.ndarray = None      # å­˜å‚¨å‘é‡
        self.metadata: List[Dict] = []       # å­˜å‚¨å…ƒæ•°æ®
        self.ids: List[str] = []            # å­˜å‚¨ID

    def add_vectors(self, vectors: np.ndarray, metadata: List[Dict], ids: List[str]):
        """æ·»åŠ å‘é‡"""
        # å®ç°å‘é‡å­˜å‚¨é€»è¾‘

    def search(self, query_vector: np.ndarray, top_k: int = 5) -> List[Dict]:
        """å‘é‡ç›¸ä¼¼æ€§æœç´¢"""
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = cosine_similarity([query_vector], self.vectors)[0]
        # è·å–top-kç»“æœ
        top_indices = np.argsort(similarities)[::-1][:top_k]
        return [self.metadata[i] for i in top_indices]
```

**ç›¸ä¼¼åº¦è®¡ç®—ï¼š**
```python
# ä½™å¼¦ç›¸ä¼¼åº¦å…¬å¼
similarity = dot(A, B) / (norm(A) * norm(B))
```

### 4.3 æ··åˆæ£€ç´¢å™¨ (hybrid_retriever.py)

```python
class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ï¼šç»“åˆå…³é”®è¯æ£€ç´¢å’Œå‘é‡æ£€ç´¢"""

    def __init__(self, knowledge_base: KnowledgeBase, vector_store: SimpleVectorStore):
        self.kb = knowledge_base
        self.vector_store = vector_store

    async def retrieve(self, query: str, top_k: int = 5) -> List[Dict]:
        """æ··åˆæ£€ç´¢ç­–ç•¥"""
        # 1. å…³é”®è¯æ£€ç´¢
        keyword_results = await self._keyword_search(query)

        # 2. å‘é‡æ£€ç´¢
        vector_results = await self._vector_search(query)

        # 3. ç»“æœèåˆ
        final_results = self._merge_results(keyword_results, vector_results)

        return final_results[:top_k]
```

**ç»“æœèåˆç­–ç•¥ï¼š**
```python
def _merge_results(self, keyword_results, vector_results):
    """ç»“æœèåˆç®—æ³•"""
    # 1. å»é‡
    seen_ids = set()
    merged = []

    # 2. å…³é”®è¯ç»“æœä¼˜å…ˆï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
    for item in keyword_results:
        if item['id'] not in seen_ids:
            item['source'] = 'keyword'
            item['relevance'] = item.get('score', 1.0)
            merged.append(item)
            seen_ids.add(item['id'])

    # 3. è¡¥å……å‘é‡ç»“æœï¼ˆè¯­ä¹‰åŒ¹é…ï¼‰
    for item in vector_results:
        if item['id'] not in seen_ids:
            item['source'] = 'vector'
            merged.append(item)
            seen_ids.add(item['id'])

    return merged
```

## 5. ç”Ÿæˆç³»ç»Ÿ (src/generation/) âš¡

### LLMç”Ÿæˆå™¨ (llm_generator.py)

```python
class LLMGenerator:
    """å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå™¨"""

    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo"):
        self.client = OpenAI(api_key=api_key)
        self.model = model

    async def generate_guidance(self, topic: WritingTopic, materials: List[WritingMaterial]) -> str:
        """ç”Ÿæˆå†™ä½œæŒ‡å¯¼"""

        # 1. æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(topic, materials)

        # 2. è°ƒç”¨LLM
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä½œæ–‡è€å¸ˆ..."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,  # æ§åˆ¶åˆ›é€ æ€§
            max_tokens=1000   # é™åˆ¶è¾“å‡ºé•¿åº¦
        )

        return response.choices[0].message.content
```

**æç¤ºè¯å·¥ç¨‹ï¼š**
```python
def _build_prompt(self, topic: WritingTopic, materials: List[WritingMaterial]) -> str:
    """æ„å»ºç»“æ„åŒ–æç¤ºè¯"""

    prompt = f"""
    é¢˜ç›®ï¼š{topic.title}
    è¦æ±‚ï¼š{topic.content}
    ç±»å‹ï¼š{topic.type}
    éš¾åº¦ï¼š{topic.difficulty}/5

    ç›¸å…³ç´ æï¼š
    """

    for i, material in enumerate(materials[:3], 1):
        prompt += f"{i}. {material.title}: {material.content[:100]}...\n"

    prompt += """
    è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›ä»¥ä¸‹æŒ‡å¯¼ï¼š
    1. å†™ä½œæ€è·¯åˆ†æ
    2. ç»“æ„å»ºè®®
    3. ç´ æä½¿ç”¨å»ºè®®
    4. æ³¨æ„äº‹é¡¹
    """

    return prompt
```

## 6. ä¸»ç³»ç»Ÿé›†æˆ (rag_system.py) ğŸ¯

```python
class RAGSystem:
    """RAGä¸»ç³»ç»Ÿï¼šæ•´åˆæ‰€æœ‰ç»„ä»¶"""

    def __init__(self, config: AppConfig):
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.config = config
        self.knowledge_base = LocalKnowledgeBase(config.knowledge_base_path)
        self.retriever = HybridRetriever(self.knowledge_base, vector_store)
        self.generator = LLMGenerator(config.openai_api_key)

    async def process_writing_request(self, topic_text: str) -> Dict[str, Any]:
        """å¤„ç†å†™ä½œè¯·æ±‚çš„å®Œæ•´æµç¨‹"""

        try:
            # 1. è§£æé¢˜ç›®
            topic = await self._parse_topic(topic_text)

            # 2. æ£€ç´¢ç›¸å…³èµ„æ–™
            materials = await self.retriever.retrieve(topic_text, top_k=5)

            # 3. ç”ŸæˆæŒ‡å¯¼å†…å®¹
            guidance = await self.generator.generate_guidance(topic, materials)

            # 4. æ„å»ºå“åº”
            return {
                "topic": topic.dict(),
                "materials": [m.dict() for m in materials],
                "guidance": guidance,
                "status": "success"
            }

        except Exception as e:
            logger.error(f"å¤„ç†è¯·æ±‚å¤±è´¥: {e}")
            return {"status": "error", "message": str(e)}
```

**ç³»ç»Ÿæµç¨‹å›¾ï¼š**
```
ç”¨æˆ·è¾“å…¥é¢˜ç›®
    â†“
è§£æé¢˜ç›®ï¼ˆæå–å…³é”®è¯ã€åˆ¤æ–­ç±»å‹ï¼‰
    â†“
æ£€ç´¢çŸ¥è¯†åº“ï¼ˆå…³é”®è¯+å‘é‡æ··åˆæ£€ç´¢ï¼‰
    â†“
ç”ŸæˆæŒ‡å¯¼ï¼ˆLLMåŸºäºæ£€ç´¢ç»“æœï¼‰
    â†“
è¿”å›ç»“æ„åŒ–ç»“æœ
```

## 7. APIæ¥å£ (src/api/main.py) ğŸŒ

### FastAPIæœåŠ¡è®¾è®¡

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(title="RAGä½œæ–‡æ•™å­¦ç³»ç»Ÿ", version="1.0.0")

class WritingRequest(BaseModel):
    """å†™ä½œè¯·æ±‚æ¨¡å‹"""
    topic: str
    student_level: Optional[int] = 3
    requirements: Optional[List[str]] = None

@app.post("/api/writing/guidance")
async def get_writing_guidance(request: WritingRequest):
    """è·å–å†™ä½œæŒ‡å¯¼"""

    try:
        # è°ƒç”¨RAGç³»ç»Ÿå¤„ç†
        result = await rag_system.process_writing_request(request.topic)
        return result

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/materials/search")
async def search_materials(query: str, limit: int = 10):
    """æœç´¢ç´ æ"""
    materials = await rag_system.knowledge_base.search_materials(query)
    return {"materials": materials[:limit]}
```

**APIè®¾è®¡åŸåˆ™ï¼š**
1. **RESTfulé£æ ¼**ï¼šèµ„æºå¯¼å‘çš„URLè®¾è®¡
2. **æ ‡å‡†HTTPçŠ¶æ€ç **ï¼š200æˆåŠŸï¼Œ400å®¢æˆ·ç«¯é”™è¯¯ï¼Œ500æœåŠ¡å™¨é”™è¯¯
3. **è¯·æ±‚éªŒè¯**ï¼šä½¿ç”¨Pydanticè‡ªåŠ¨éªŒè¯å’Œåºåˆ—åŒ–
4. **é”™è¯¯å¤„ç†**ï¼šç»Ÿä¸€çš„é”™è¯¯å“åº”æ ¼å¼

## ğŸš€ è¿è¡Œå’Œè°ƒè¯•

### 1. ç¯å¢ƒé…ç½®æ£€æŸ¥

```python
# simple_demo.py - æœ€å°åŒ–æµ‹è¯•
import asyncio
from src.rag_system import RAGSystem
from src.core.config import AppConfig

async def test_basic_functionality():
    """åŸºç¡€åŠŸèƒ½æµ‹è¯•"""
    config = AppConfig()
    rag = RAGSystem(config)

    await rag.initialize()

    result = await rag.process_writing_request("å†™ä¸€ç¯‡å…³äºå‹è°Šçš„ä½œæ–‡")
    print(f"ç»“æœ: {result}")

if __name__ == "__main__":
    asyncio.run(test_basic_functionality())
```

### 2. è°ƒè¯•æŠ€å·§

```python
import logging

# è®¾ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# åœ¨å…³é”®ä½ç½®æ·»åŠ æ—¥å¿—
logger.debug(f"æ£€ç´¢åˆ° {len(materials)} æ¡ç´ æ")
logger.info(f"æ­£åœ¨ä¸ºé¢˜ç›® '{topic.title}' ç”ŸæˆæŒ‡å¯¼")
```

### 3. å¸¸è§é—®é¢˜è§£å†³

#### å¯¼å…¥é”™è¯¯
```python
# æ–¹æ¡ˆ1ï¼šä½¿ç”¨ç»å¯¹å¯¼å…¥
from src.core.models import WritingTopic

# æ–¹æ¡ˆ2ï¼šæ·»åŠ è·¯å¾„
import sys
sys.path.append('/Users/admin/Desktop/Work/ggame/article-rag')
```

#### ä¾èµ–åŒ…é—®é¢˜
```bash
# æ£€æŸ¥å·²å®‰è£…åŒ…
pip list | grep pydantic

# é‡æ–°å®‰è£…
pip install --upgrade pydantic
```

## ğŸ¯ å­¦ä¹ å»ºè®®

### æ–°æ‰‹å­¦ä¹ è·¯å¾„ï¼š
1. **å…ˆè·‘é€šdemo**ï¼šç¡®ä¿basic functionalityå·¥ä½œ
2. **ç†è§£æ•°æ®æ¨¡å‹**ï¼šmodels.pyæ˜¯æ ¸å¿ƒ
3. **è·Ÿè¸ªä¸€ä¸ªå®Œæ•´æµç¨‹**ï¼šä»è¾“å…¥åˆ°è¾“å‡º
4. **ä¿®æ”¹å’Œå®éªŒ**ï¼šæ”¹å˜å‚æ•°çœ‹æ•ˆæœ
5. **æ‰©å±•åŠŸèƒ½**ï¼šæ·»åŠ æ–°çš„ç´ æç±»å‹

### è¿›é˜¶å­¦ä¹ ï¼š
1. **æ€§èƒ½ä¼˜åŒ–**ï¼šç¼“å­˜ã€æ‰¹å¤„ç†ã€å¼‚æ­¥
2. **åŠŸèƒ½æ‰©å±•**ï¼šæ”¯æŒå›¾ç‰‡ã€éŸ³é¢‘ç´ æ
3. **æ¨¡å‹å¾®è°ƒ**ï¼šè®­ç»ƒä¸“é—¨çš„æ•™è‚²é¢†åŸŸæ¨¡å‹
4. **ç”¨æˆ·ç•Œé¢**ï¼šæ·»åŠ Webå‰ç«¯

### ä»£ç è´¨é‡æå‡ï¼š
1. **æ·»åŠ æµ‹è¯•**ï¼šå•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•
2. **å¼‚å¸¸å¤„ç†**ï¼šæ›´å®Œå–„çš„é”™è¯¯å¤„ç†
3. **æ–‡æ¡£å®Œå–„**ï¼šä»£ç æ³¨é‡Šã€APIæ–‡æ¡£
4. **ä»£ç è§„èŒƒ**ï¼šä½¿ç”¨blackã€flake8ç­‰å·¥å…·

---

## ğŸ“ æ€»ç»“

è¿™ä¸ªRAGä½œæ–‡æ•™å­¦ç³»ç»Ÿä½“ç°äº†ç°ä»£è½¯ä»¶æ¶æ„çš„å‡ ä¸ªé‡è¦åŸåˆ™ï¼š

1. **æ¨¡å—åŒ–è®¾è®¡**ï¼šå„æ¨¡å—èŒè´£æ¸…æ™°ï¼Œä½è€¦åˆé«˜å†…èš
2. **æŠ½è±¡æ¥å£**ï¼šä¾¿äºæ‰©å±•å’Œæ›¿æ¢å®ç°
3. **é…ç½®ç®¡ç†**ï¼šç¯å¢ƒå˜é‡ã€é…ç½®æ–‡ä»¶åˆ†ç¦»
4. **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
5. **å¼‚æ­¥ç¼–ç¨‹**ï¼šæé«˜ç³»ç»Ÿæ€§èƒ½å’Œç”¨æˆ·ä½“éªŒ

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œä½ ä¸ä»…å­¦ä¼šäº†RAGæŠ€æœ¯çš„å®ç°ï¼Œæ›´é‡è¦çš„æ˜¯æŒæ¡äº†å¦‚ä½•æ„å»ºä¸€ä¸ªå®Œæ•´çš„ã€å¯ç»´æŠ¤çš„AIåº”ç”¨ç³»ç»Ÿã€‚

**ä¸‹ä¸€æ­¥å»ºè®®ï¼š**
- è¿è¡Œsimple_demo.pyéªŒè¯ç³»ç»Ÿå·¥ä½œ
- é˜…è¯»å’Œä¿®æ”¹å…·ä½“æ¨¡å—ä»£ç 
- å°è¯•æ·»åŠ æ–°åŠŸèƒ½
- éƒ¨ç½²åˆ°äº‘æœåŠ¡å™¨

ç¥ä½ å­¦ä¹ æ„‰å¿«ï¼ğŸ‰
